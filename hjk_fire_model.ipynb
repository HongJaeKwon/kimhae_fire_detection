{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hjk_fire_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HongJaeKwon/kimhae_fire_detection/blob/master/hjk_fire_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWB7bto-B1V9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "c2388c88-c728-40bf-dc66-c23654f02be7"
      },
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "# /gdrive/My Drive/ (폴더명)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSA-hQtcOsTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "da0b8422-106a-4973-f66b-4fc8a47b5410"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from  sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.python.keras.layers import Conv2D, Conv2DTranspose, Activation, Flatten, Dense, UpSampling2D, Reshape, Lambda, Input,BatchNormalization, Dropout, LeakyReLU\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, Iterator\n",
        "from tensorflow.python.keras.preprocessing.image import img_to_array, array_to_img\n",
        "from tensorflow.python.keras.losses import mean_absolute_error\n",
        "warnings.filterwarnings(action='ignore') "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0okDWH7vxL9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def hjk_loss(y_true,y_pred):\n",
        "    bce = 3*y_true * K.log(y_pred + K.epsilon())\n",
        "    bce += (1 - y_true) * K.log(1 - y_pred + K.epsilon())\n",
        "    return -bce\n",
        "\n",
        "def f1_loss(y_true, y_pred):\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = K.clip(f1,K.epsilon(),1-K.epsilon())\n",
        "    return 1 - K.mean(f1)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1E4EBOpxapG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "50bd48ce-3a5a-4b6b-f172-f95874644075"
      },
      "source": [
        "cnn_model=Sequential()\n",
        "cnn_model.add(Dense(16*16,activation='relu',input_shape=(200,)))\n",
        "cnn_model.add(Reshape((16,16,1)))\n",
        "cnn_model.add(Conv2D(2, 3, activation='elu', strides=2, padding='same'))\n",
        "cnn_model.add(Conv2D(4, 3, activation='elu', strides=2, padding='same'))\n",
        "cnn_model.add(Conv2D(8, 3, activation='elu', strides=2, padding='same'))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(1,activation='sigmoid'))\n",
        "cnn_model.compile(loss=hjk_loss, metrics=['acc',f1_m, precision_m, recall_m],optimizer=Adam(0.001))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03rcT6_Ntlmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_DF= pd.read_csv('/gdrive/My Drive/김해화재/all_DF.csv',index_col=0)\n",
        "# train :59199\n",
        "# val : 6898\n",
        "# test : 2957"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV1VshIyt-p1",
        "colab_type": "code",
        "outputId": "24669312-a888-4e02-b0fb-faafeb915cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "all_DF.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>397</th>\n",
              "      <th>398</th>\n",
              "      <th>399</th>\n",
              "      <th>400</th>\n",
              "      <th>401</th>\n",
              "      <th>402</th>\n",
              "      <th>403</th>\n",
              "      <th>404</th>\n",
              "      <th>405</th>\n",
              "      <th>406</th>\n",
              "      <th>407</th>\n",
              "      <th>408</th>\n",
              "      <th>409</th>\n",
              "      <th>410</th>\n",
              "      <th>411</th>\n",
              "      <th>412</th>\n",
              "      <th>413</th>\n",
              "      <th>414</th>\n",
              "      <th>415</th>\n",
              "      <th>416</th>\n",
              "      <th>417</th>\n",
              "      <th>418</th>\n",
              "      <th>419</th>\n",
              "      <th>420</th>\n",
              "      <th>421</th>\n",
              "      <th>422</th>\n",
              "      <th>423</th>\n",
              "      <th>424</th>\n",
              "      <th>425</th>\n",
              "      <th>426</th>\n",
              "      <th>427</th>\n",
              "      <th>428</th>\n",
              "      <th>429</th>\n",
              "      <th>430</th>\n",
              "      <th>431</th>\n",
              "      <th>432</th>\n",
              "      <th>433</th>\n",
              "      <th>434</th>\n",
              "      <th>435</th>\n",
              "      <th>LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.200443</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.043593</td>\n",
              "      <td>0.002841</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009122</td>\n",
              "      <td>0.039669</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.059644</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.006703</td>\n",
              "      <td>0.002841</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066623</td>\n",
              "      <td>0.040868</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>0.000196</td>\n",
              "      <td>0.000278</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>0.000318</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>0.00023</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.000201</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.000357</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>0.001119</td>\n",
              "      <td>0.001137</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.220430</td>\n",
              "      <td>0.001019</td>\n",
              "      <td>0.038322</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.013439</td>\n",
              "      <td>0.042426</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.007205</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.044794</td>\n",
              "      <td>0.001420</td>\n",
              "      <td>0.130952</td>\n",
              "      <td>0.010669</td>\n",
              "      <td>0.034756</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.221068</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.043593</td>\n",
              "      <td>0.001420</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.055872</td>\n",
              "      <td>0.040868</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000099</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>0.000196</td>\n",
              "      <td>0.000278</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>0.000318</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>0.00023</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.000201</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000228</td>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>0.000357</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>0.000368</td>\n",
              "      <td>0.000373</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>0.001119</td>\n",
              "      <td>0.001137</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 437 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4  ...  432  433  434  435  LABEL\n",
              "0  0.200443  0.000121  0.043593  0.002841  0.000000  ...  0.0  1.0  0.0  0.0    1.0\n",
              "1  0.059644  0.000081  0.006703  0.002841  0.000000  ...  0.0  0.0  0.0  1.0    0.0\n",
              "2  0.220430  0.001019  0.038322  0.000000  0.166667  ...  0.0  0.0  0.0  1.0    1.0\n",
              "3  0.007205  0.000085  0.044794  0.001420  0.130952  ...  0.0  0.0  0.0  0.0    0.0\n",
              "4  0.221068  0.000000  0.043593  0.001420  0.000000  ...  0.0  0.0  0.0  1.0    0.0\n",
              "\n",
              "[5 rows x 437 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UdfmxAkuij7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_DF=all_DF[:59199]\n",
        "val_DF=all_DF[59199:59199+6898]\n",
        "test_DF=all_DF[all_DF['LABEL']==-1]\n",
        "\n",
        "train_DF_Y=train_DF['LABEL']\n",
        "val_DF_Y=val_DF['LABEL']\n",
        "train_DF_normal=train_DF[train_DF['LABEL']==0]\n",
        "train_DF_fire=train_DF[train_DF['LABEL']==1]\n",
        "\n",
        "train_DF=train_DF.drop('LABEL', axis = 1)\n",
        "val_DF=val_DF.drop('LABEL', axis = 1)\n",
        "test_DF=test_DF.drop('LABEL', axis = 1)\n",
        "\n",
        "train_DF_normal=train_DF_normal.drop('LABEL', axis = 1)\n",
        "train_DF_fire=train_DF_fire.drop('LABEL', axis = 1)\n",
        "\n",
        "train_DF_1=train_DF[:30000]\n",
        "train_DF_Y_1=train_DF_Y[:30000]\n",
        "train_DF_2=train_DF[30000:]\n",
        "train_DF_Y_2=train_DF_Y[30000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HleGfgoTKQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_list=train_DF.columns.to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMGznOPkJz_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stack_DF=pd.DataFrame()\n",
        "stack_DF_val=pd.DataFrame()\n",
        "stack_DF_test=pd.DataFrame()\n",
        "lda=LinearDiscriminantAnalysis()\n",
        "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=5)\n",
        "rf_clf = RandomForestClassifier(n_jobs=-1, n_estimators=100, random_state=42)\n",
        "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHjqOT1VS6wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "for i in range(5):\n",
        "    print(i)\n",
        "    rnd_list=np.random.choice(col_list, 200, replace=False)\n",
        "    \n",
        "    lda=lda.fit(train_DF_1[rnd_list], train_DF_Y_1)\n",
        "    stack_DF['lda'+str(i)]=np.reshape(lda.transform(train_DF_2[rnd_list]),(-1,))\n",
        "    stack_DF_val['lda'+str(i)]=np.reshape(lda.transform(val_DF[rnd_list]),(-1,))\n",
        "    stack_DF_test['lda'+str(i)]=np.reshape(lda.transform(test_DF[rnd_list]),(-1,))\n",
        "    \n",
        "    decision_tree = decision_tree.fit(train_DF_1[rnd_list], train_DF_Y_1)\n",
        "    stack_DF['dt'+str(i)]=np.reshape(decision_tree.predict_proba(train_DF_2[rnd_list])[:,1],(-1,))\n",
        "    stack_DF_val['dt'+str(i)]=np.reshape(decision_tree.predict_proba(val_DF[rnd_list])[:,1],(-1,))\n",
        "    stack_DF_test['dt'+str(i)]=np.reshape(decision_tree.predict_proba(test_DF[rnd_list])[:,1],(-1,))\n",
        "\n",
        "    rf_clf = rf_clf.fit(train_DF_1[rnd_list], train_DF_Y_1)\n",
        "    stack_DF['rf'+str(i)]=np.reshape(rf_clf.predict_proba(train_DF_2[rnd_list])[:,1],(-1,))\n",
        "    stack_DF_val['rf'+str(i)]=np.reshape(rf_clf.predict_proba(val_DF[rnd_list])[:,1],(-1,))\n",
        "    stack_DF_test['rf'+str(i)]=np.reshape(rf_clf.predict_proba(test_DF[rnd_list])[:,1],(-1,))\n",
        "\n",
        "    xgb_model = xgb_model.fit(train_DF_1[rnd_list], train_DF_Y_1)\n",
        "    stack_DF['xgb'+str(i)]=np.reshape(xgb_model.predict_proba(train_DF_2[rnd_list])[:,1],(-1,))\n",
        "    stack_DF_val['xgb'+str(i)]=np.reshape(xgb_model.predict_proba(val_DF[rnd_list])[:,1],(-1,))\n",
        "    stack_DF_test['xgb'+str(i)]=np.reshape(xgb_model.predict_proba(test_DF[rnd_list])[:,1],(-1,))\n",
        "\n",
        "    cnn_model.fit(train_DF_1[rnd_list].as_matrix(),train_DF_Y_1.as_matrix(),epochs=50,verbose=0)\n",
        "    stack_DF['cnn'+str(i)]=np.reshape(cnn_model.predict(train_DF_2[rnd_list].as_matrix()),(-1,))\n",
        "    stack_DF_val['cnn'+str(i)]=np.reshape(cnn_model.predict(val_DF[rnd_list].as_matrix()),(-1,))\n",
        "    stack_DF_test['cnn'+str(i)]=np.reshape(cnn_model.predict(test_DF[rnd_list].as_matrix()),(-1,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aec5iZdOMfJn",
        "colab_type": "code",
        "outputId": "544e3e85-ddbd-492d-ffb3-d0afe19b00e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "stack_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
        "stack_model.fit(stack_DF, train_DF_Y_2)\n",
        "y_pred=stack_model.predict(stack_DF_val)\n",
        "print (\"accuracy_score : \" , accuracy_score(val_DF_Y, y_pred))\n",
        "print (\"f1_score : \" , f1_score(val_DF_Y, y_pred))\n",
        "print (\"precision_score : \" , precision_score(val_DF_Y, y_pred))\n",
        "print (\"recall_score : \" , recall_score(val_DF_Y, y_pred))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score :  0.7987822557262975\n",
            "f1_score :  0.5088464260438783\n",
            "precision_score :  0.4626769626769627\n",
            "recall_score :  0.565251572327044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRUrxtvn8HaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from imblearn.over_sampling import SMOTE\n",
        "# sm = SMOTE(ratio='auto', kind='regular')\n",
        "# X_resampled, y_resampled = sm.fit_sample(stack_DF,list(train_DF_Y_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APsoLydN9mk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "fa5a5772-2f81-4605-8789-821a3a528d78"
      },
      "source": [
        "# stack_model.fit(X_resampled, y_resampled)\n",
        "# y_pred=stack_model.predict(stack_DF_val.as_matrix())\n",
        "# print (\"accuracy_score : \" , accuracy_score(val_DF_Y, y_pred))\n",
        "# print (\"f1_score : \" , f1_score(val_DF_Y, y_pred))\n",
        "# print (\"precision_score : \" , precision_score(val_DF_Y, y_pred))\n",
        "# print (\"recall_score : \" , recall_score(val_DF_Y, y_pred))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_score :  0.6175703102348507\n",
            "f1_score :  0.4343910806174957\n",
            "precision_score :  0.2986438679245283\n",
            "recall_score :  0.7963836477987422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngdFBVNCO3xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=stack_model.predict(stack_DF_test)\n",
        "sub = pd.read_csv('/gdrive/My Drive/김해화재/PJT002_submission.csv')\n",
        "sub['fr_yn'] = y_pred\n",
        "sub['fr_yn'] = sub['fr_yn'].map({0:'N', 1:'Y'})\n",
        "sub.to_csv('/gdrive/My Drive/김해화재/PJT002_submission_hjk_stack2.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVlL00Cq_SKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_encoder():\n",
        "    model=Sequential()\n",
        "    model.add(Dense(16*16,activation='relu',input_shape=(436,)))\n",
        "    model.add(Reshape((16,16,1)))\n",
        "    model.add(Conv2D(2, 3, activation='elu', strides=2, padding='same'))\n",
        "    model.add(Conv2D(4, 3, activation='elu', strides=2, padding='same'))\n",
        "    model.add(Conv2D(8, 3, activation='elu', strides=2, padding='same'))\n",
        "    return model\n",
        "\n",
        "def build_decoder():\n",
        "    model=Sequential()\n",
        "    model.add(Conv2D(4, 3, activation='elu', padding='same'))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Conv2D(2, 3, activation='elu', padding='same'))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Conv2D(1, 3, activation='elu', padding='same'))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(LeakyReLU(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(436,activation='sigmoid'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mg3hJsGCs_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = build_encoder()\n",
        "decoder = build_decoder()\n",
        "AE_model=Sequential((encoder, decoder))\n",
        "AE_model.compile(loss='mse',optimizer=Adam(0.001))\n",
        "AE_model.fit(train_DF_fire.as_matrix(),train_DF_fire.as_matrix(),epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaNAN_1rH85L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1b3a7ed4-f26e-4d69-89dd-5a195e9cdb57"
      },
      "source": [
        "AE_model.evaluate(train_DF_normal.as_matrix(),train_DF_normal.as_matrix())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51542/51542 [==============================] - 3s 58us/sample - loss: 0.0117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01173343503237919"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiMVhlxWGRcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fire=encoder.predict(train_DF_fire.as_matrix())\n",
        "non_fire=encoder.predict(train_DF_normal.as_matrix())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl3kWzAQGY1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fire=np.reshape(fire,(-1,32))\n",
        "non_fire=np.reshape(non_fire,(-1,32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mytyl-hFG9vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(32):\n",
        "    print(i)\n",
        "    print(\"fire 평균\",np.mean(fire[:,i]))\n",
        "    print(\"fire 편차\",np.std(fire[:,i]))\n",
        "    print(\"non-fire 평균\",np.mean(non_fire[:,i]))\n",
        "    print(\"non-fire 편차\",np.std(non_fire[:,i]))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}